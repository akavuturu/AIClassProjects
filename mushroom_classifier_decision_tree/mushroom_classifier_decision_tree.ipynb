{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "from math import log2\n",
    "from typing import List, Dict, Tuple, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For this assignment you will be implementing and evaluating a Decision Tree using the ID3 Algorithm (**no** pruning or normalized information gain). Use the provided pseudocode. The data is located at (copy link):\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "**Just in case** the UCI repository is down, which happens from time to time, I have included the data and name files on Blackboard.\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Important</strong>\n",
    "    <p>\n",
    "        No Pandas. The only acceptable libraries in this class are those contained in the `environment.yml`. No OOP, either. You can used Dicts, NamedTuples, etc. as your abstract data type (ADT) for the the tree and nodes.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "One of the things we did not talk about in the lectures was how to deal with missing values. There are two aspects of the problem here. What do we do with missing values in the training data? What do we do with missing values when doing classifcation?\n",
    "\n",
    "There are a lot of different ways that we can handle this.\n",
    "A common algorithm is to use something like kNN to impute the missing values.\n",
    "We can use conditional probability as well.\n",
    "There are also clever modifications to the Decision Tree algorithm itself that one can make.\n",
    "\n",
    "We're going to do something simpler, given the size of the data set: remove the observations with missing values (\"?\").\n",
    "\n",
    "You must implement the following functions:\n",
    "\n",
    "`train` takes training_data and returns the Decision Tree as a data structure.\n",
    "\n",
    "```\n",
    "def train(training_data):\n",
    "   # returns the Decision Tree.\n",
    "```\n",
    "\n",
    "`classify` takes a tree produced from the function above and applies it to labeled data (like the test set) or unlabeled data (like some new data).\n",
    "\n",
    "```\n",
    "def classify(tree, observations, labeled=True):\n",
    "    # returns a list of classifications\n",
    "```\n",
    "\n",
    "`evaluate` takes a data set with labels (like the training set or test set) and the classification result and calculates the classification error rate:\n",
    "\n",
    "$$error\\_rate=\\frac{errors}{n}$$\n",
    "\n",
    "Do not use anything else as evaluation metric or the submission will be deemed incomplete, ie, an \"F\". (Hint: accuracy rate is not the error rate!).\n",
    "\n",
    "`cross_validate` takes the data and uses 10 fold cross validation (from Module 3!) to `train`, `classify`, and `evaluate`. **Remember to shuffle your data before you create your folds**. I leave the exact signature of `cross_validate` to you but you should write it so that you can use it with *any* `classify` function of the same form (using higher order functions and partial application).\n",
    "\n",
    "Following Module 3's assignment, `cross_validate` should print out a table in exactly the same format. What you are looking for here is a consistent evaluation metric cross the folds. Print the error rate to 4 decimal places. **Do not convert to a percentage.**\n",
    "\n",
    "```\n",
    "def pretty_print_tree(tree):\n",
    "    # pretty prints the tree\n",
    "```\n",
    "\n",
    "This should be a text representation of a decision tree trained on the entire data set (no train/test).\n",
    "\n",
    "To summarize...\n",
    "\n",
    "Apply the Decision Tree algorithm to the Mushroom data set using 10 fold cross validation and the error rate as the evaluation metric. When you are done, apply the Decision Tree algorithm to the entire data set and print out the resulting tree.\n",
    "\n",
    "**Note** Because this assignment has a natural recursive implementation, you should consider using `deepcopy` at the appropriate places.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The data is given in \"agaricus-lepiota.data\" as a text file - each line in the text file is a single observation, with a total of 8124 observations, each with 22 attributes.\n",
    "\n",
    "| Index | Variable                  | Description |\n",
    "| ----- | -----------               | ----------- |\n",
    "| 0     | **class label**           | edible=e,poisonous=p |\n",
    "| 1     | cap-shape                 | bell=b,conical=c,convex=x,flat=f,knobbed=k,sunken=s\n",
    "| 2     | cap-surface               | fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "| 3     | cap-color                 | brown=n,buff=b,cinnamon=c,gray=g,green=r,\n",
    "|       |                           | pink=p,purple=u,red=e,white=w,yellow=y\n",
    "| 4     | bruises?                  | bruises=t,no=f\n",
    "| 5     | odor                      | almond=a,anise=l,creosote=c,fishy=y,foul=f,\n",
    "|       |                           | musty=m,none=n,pungent=p,spicy=s\n",
    "| 6     | gill-attachment           | attached=a,descending=d,free=f,notched=n\n",
    "| 7     | gill-spacing              | close=c,crowded=w,distant=d\n",
    "| 8     | gill-size                 | broad=b,narrow=n\n",
    "| 9     | gill-color                | black=k,brown=n,buff=b,chocolate=h,gray=g,\n",
    "|       |                           | green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "| 10    | stalk-shape               | enlarging=e,tapering=t\n",
    "| 11    | stalk-root                | bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?\n",
    "| 12    | stalk-surface-above-ring  | fibrous=f,scaly=y,silky=k,smooth=s\n",
    "| 13    | stalk-surface-below-ring  | fibrous=f,scaly=y,silky=k,smooth=s\n",
    "| 14    | stalk-color-above-ring    | brown=n,buff=b,cinnamon=c,gray=g,orange=o,\n",
    "|       |                           | pink=p,red=e,white=w,yellow=y\n",
    "| 15    | stalk-color-below-ring    | brown=n,buff=b,cinnamon=c,gray=g,orange=o,\n",
    "|       |                           | pink=p,red=e,white=w,yellow=y\n",
    "| 16    | veil-type                 | partial=p,universal=u\n",
    "| 17    | veil-color                | brown=n,orange=o,white=w,yellow=y\n",
    "| 18    | ring-number               | none=n,one=o,two=t\n",
    "| 19    | ring-type                 | cobwebby=c,evanescent=e,flaring=f,large=l,\n",
    "|       |                           | none=n,pendant=p,sheathing=s,zone=z\n",
    "| 20    | spore-print-color         | black=k,brown=n,buff=b,chocolate=h,green=r,\n",
    "|       |                           | orange=o,purple=u,white=w,yellow=y\n",
    "| 21    | population                | abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
    "| 22    | habitat                   | grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d\n",
    "\n",
    "The 11th attribute has possible missing data, denoted by a \"?\" - any observations with missing data will not be included in the dataset. The class label is the first element in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three functions are taken from Programming Assignment 3 to parse data, create folds in data, and separate the data into training and test sets. The `parse_data` function is augmented to generate lists of characters rather than floats, and excludes rows with \"?\" characters.\n",
    "\n",
    "The tree is implemented as a list of tuples of the form `(Attribute_name, Attribute_value, child)`. For a tree of the following shape, with attributes in order as X, Y, Z:\n",
    "\n",
    "```.\n",
    "└── A/\n",
    "    ├── B/\n",
    "    │   ├── C\n",
    "    │   └── D\n",
    "    └── E/\n",
    "        ├── F\n",
    "        └── G\n",
    "```\n",
    "\n",
    "We would represent this as: \n",
    "```\n",
    "[(X, A, \n",
    "    [(Y, B, \n",
    "        [(Z, C, \"\"), \n",
    "         (Z, D, \"\")]), \n",
    "     (Y, E, \n",
    "        [(Z, F, \"\"), \n",
    "         (Z, G, \"\")]\n",
    "     )\n",
    "    ]\n",
    "   )\n",
    " ]\n",
    "```\n",
    "\n",
    "Here, leaf nodes have a single element for their `child` value, and internal nodes have a list of tuples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"parse_data\"></a>\n",
    "## parse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> List[List]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [value for value in line.rstrip().split(\",\")]\n",
    "        if \"?\" not in datum: data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5644"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = parse_data(\"agaricus-lepiota.data\")\n",
    "len(data) # 8124 observations, 2480 observations with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 'f', 'y', 'g', 't', 'n', 'f', 'c', 'b', 'u', 't', 'b', 's', 's', 'g', 'w', 'p', 'w', 'o', 'p', 'n', 'y', 'd']\n"
     ]
    }
   ],
   "source": [
    "print(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_folds\"></a>\n",
    "## create_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(xs: List, n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(xs), n)\n",
    "    # be careful of generators...\n",
    "    return list(xs[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = create_folds(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_train_test\"></a>\n",
    "## create_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(folds: List[List[List]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = create_train_test(folds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5079"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"is_homogenous\"></a>\n",
    "## is_homogenous\n",
    "\n",
    "`is_homogeneous` takes a dataset and returns whether it is homogeneous (whether all class labels are the same). This check is one of the base cases of the `id3` algorithm and determines whether branching needs to occur on the given dataset, or whether a class label can be assigned to the dataset in the decision tree. **Used by**: [id3](#id3).\n",
    "\n",
    "* **data**: the dataset to determine homogeneity of\n",
    "\n",
    "**returns** `bool`: whether the dataset is homogeneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_homogeneous(data) -> bool:\n",
    "    curr_label = data[0][0] if data and data[0] else \"\"\n",
    "    return all([row[0] == curr_label for row in data]) and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "data = [['y', 's', 'l', 'g'],\n",
    "        ['y', 's', 's', 'g'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 'r', 's', 'g']]\n",
    "assert is_homogeneous(data)\n",
    "\n",
    "data = [['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 's', 'g'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 'r', 's', 'g']]\n",
    "assert not is_homogeneous(data)\n",
    "\n",
    "assert not is_homogeneous([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"majority_label\"></a>\n",
    "## majority_label\n",
    "\n",
    "`majority_label` takes a dataset and returns the majority class label - this is used as a class label for non-homogeneous base cases, where the dataset has no more attributes left to split on. **Used by**: [id3](#id3). [train](#train).\n",
    "\n",
    "* **data**: the dataset to find the majority_label of\n",
    "\n",
    "**returns** `str`: the majority class label of `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_label(data) -> str:\n",
    "    label_counts = {}\n",
    "    for row in data:\n",
    "        label_counts[row[0]] = label_counts[row[0]] if row[0] in label_counts else 1\n",
    "    return max(label_counts, key=label_counts.get) if label_counts else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "data = [['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 's', 'g'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 'r', 's', 'g']]\n",
    "\n",
    "label = majority_label(data)\n",
    "assert label == \"y\"\n",
    "\n",
    "data = [['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 's', 'g'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['n', 's', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 'r', 's', 'g']]\n",
    "label = majority_label(data)\n",
    "assert label == \"y\"\n",
    "\n",
    "assert majority_label([]) == \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"set_entropy\"></a>\n",
    "## set_entropy\n",
    "\n",
    "`set_entropy` determines the entropy of the given set. Entropy is defined by the formula: \n",
    "$$E = -\\sum_i \\frac{p_i}{n}\\log_2(\\frac{p_i}{n})$$\n",
    "\n",
    "$p_i$ is the number of observations with class label `i`, and we sum this over all class labels. This is a measure of how homogeneous the dataset is, with 0 being a homogeneous dataset and 1 being a perfectly split dataset (50/50). Entropy is used to determine information gain in the `id3` algorithm. **Used by**: [pick_best_attr](#pick_best_attr).\n",
    "\n",
    "* **dataset**: the dataset to compute the entropy of\n",
    "\n",
    "**returns** `float`: the entropy of `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_entropy(dataset) -> float:\n",
    "    counts = {}\n",
    "    for row in dataset:\n",
    "        counts[row[0]] = counts.get(row[0], 0) + 1\n",
    "    total_count = sum(counts.values())\n",
    "    entropy = 0\n",
    "    for val in counts.keys():\n",
    "        entropy += (counts[val] / total_count)*log2((counts[val] / total_count))\n",
    "    return -entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 's', 'g'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 'r', 's', 'g']]\n",
    "e_s = set_entropy(data)\n",
    "assert abs(e_s - 0.918) < 0.005\n",
    "\n",
    "data = [['n', 'r', 'l', 'b'],\n",
    "        ['n', 's', 's', 'b'],\n",
    "        ['n', 'r', 's', 'b']]\n",
    "e_s = set_entropy(data)\n",
    "assert e_s == 0\n",
    "\n",
    "data = [['n', 's', 's', 'r'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['y', 'r', 's', 'r'],\n",
    "        ['n', 's', 'l', 'r'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['n', 's', 's', 'r']]\n",
    "e_s = set_entropy(data)\n",
    "assert e_s == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"find_subset\"></a>\n",
    "## find_subset\n",
    "\n",
    "`find_subset` takes a set of `data` and an attribute/value pair and returns a subset of `data` where the value of `best_attr` for each observation is `value`. In other words, it takes only data that has the given value for the given attribute from `data`. These subsets are used for both computing entropies as well as narrowing down the dataset in the recursive portion of the `id3` algorithm. \n",
    "\n",
    "In finding the entropy of a heterogeneous dataset, we can iteratively take the subsets matching each attribute and compute the entropies for each subset and compute their weighted sum in order to find the total information gain for splitting on one attribute (for example, if we had the attribute `Shape`, we would iteratively find subsets that matched to values `square` and `round`, compute entropies for each, and total them for the weighted sum entropy of `Shape`). **Used by**: [pick_best_attr](#pick_best_attr), [id3](#id3).\n",
    "\n",
    "* **data**: the data to find a subset from\n",
    "* **best_attr**: the attribute as a column index in `data`\n",
    "* **value**: the chosen value for `best_attr` to match\n",
    "\n",
    "**returns** `List`: a subset of `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subset(data, best_attr, value) -> List:\n",
    "    subset = []\n",
    "    for row in data:\n",
    "        if row[best_attr] == value:\n",
    "            subset.append(deepcopy(row))\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "data = [[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "        [\"b\", \"e\", \"b\", \"c\", \"d\"],\n",
    "        [\"a\", \"f\", \"g\", \"h\", \"i\"],\n",
    "        [\"a\", \"e\", \"x\", \"e\", \"f\"]]\n",
    "subset = find_subset(data, 1, \"b\")\n",
    "assert subset == [data[0]]\n",
    "\n",
    "data = [[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "        [\"b\", \"e\", \"b\", \"c\", \"d\"],\n",
    "        [\"a\", \"f\", \"g\", \"h\", \"i\"],\n",
    "        [\"a\", \"e\", \"x\", \"e\", \"f\"],\n",
    "        [\"x\", \"e\", \"f\", \"g\", \"n\"]]\n",
    "subset = find_subset(data, 1, \"e\")\n",
    "assert subset == [[\"b\", \"e\", \"b\", \"c\", \"d\"], [\"a\", \"e\", \"x\", \"e\", \"f\"], [\"x\", \"e\", \"f\", \"g\", \"n\"]]\n",
    "\n",
    "data = [[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "        [\"b\", \"e\", \"b\", \"c\", \"d\"],\n",
    "        [\"a\", \"f\", \"g\", \"h\", \"i\"],\n",
    "        [\"a\", \"e\", \"x\", \"e\", \"f\"]]\n",
    "subset = find_subset(data, 0, \"c\")\n",
    "assert not subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pick_best_attr\"></a>\n",
    "## pick_best_attr\n",
    "\n",
    "`pick_best_attr` is the method by which `id3` chooses which attribute to recurse on next. By computing the information gain, which is the difference in start entropy and entropy after splitting on any given attribute, we can determine which attribute gives us the most information (and which we should split on next). The function iterates over every attribute in `attributes` and computes this information gain by taking subsets of `data` for each value in the domain of each attribute. Finally, computing the weighted sum of each attribute value's entropy, we can compute information gain by taking the difference between the attribute entropy and the starting entropy. The function returns the attribute with the highest information gain. **Used by**: [id3](#id3).\n",
    "\n",
    "* **data**: the starting dataset\n",
    "* **attributes**: the remaining attributes to split on\n",
    "* **domains**: a list of all values for each attribute\n",
    "\n",
    "**returns** `int`: the attribute index which yields the highest information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_attr(data, attributes, domains) -> int:\n",
    "    e_start = set_entropy(data)    \n",
    "    curr_entropy, attr_entropies, info_gain = 0, {}, {}\n",
    "    for attr in attributes:\n",
    "        curr_entropy = 0\n",
    "        for attr_val in domains[attr]:\n",
    "            subset = find_subset(data, attr, attr_val)\n",
    "            curr_entropy += set_entropy(subset)*(len(subset)/(len(data)))\n",
    "        attr_entropies[attr] = curr_entropy\n",
    "        info_gain[attr] = e_start - curr_entropy\n",
    "    return max(info_gain, key=info_gain.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "data = [['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 's', 'g'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 'r', 's', 'g']]\n",
    "attributes = [1, 2]\n",
    "domains = [['y', 'n'], ['s', 'r'], ['l', 's'], ['g', 'r', 'b']]\n",
    "best_attr = pick_best_attr(data, attributes, domains)\n",
    "assert best_attr == 2\n",
    "\n",
    "data = [['n', 's', 's', 'r'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['y', 'r', 's', 'r'],\n",
    "        ['n', 's', 'l', 'r'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['n', 's', 's', 'r']]\n",
    "best_attr = pick_best_attr(data, attributes, domains)\n",
    "assert best_attr == 1\n",
    "\n",
    "data = [['n', 'r', 'l', 'b'], \n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 's', 'r'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['n', 's', 's', 'b'],\n",
    "        ['n', 'r', 's', 'b'],\n",
    "        ['y', 'r', 's', 'r'],\n",
    "        ['n', 's', 's', 'g'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 'l', 'r'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['n', 's', 's', 'r'],\n",
    "        ['n', 'r', 's', 'g']]\n",
    "attributes = [1, 2, 3]\n",
    "best_attr = pick_best_attr(data, attributes, domains)\n",
    "assert best_attr == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"attribute_minus\"></a>\n",
    "## attribute_minus\n",
    "\n",
    "`attribute_minus` returns `attributes` without `best_attr` - this is a helper function to remove attributes that have already been split on in `id3`. **Used by**: [id3](#id3).\n",
    "\n",
    "* **attributes**: the list of current attributes\n",
    "* **best_attr**: the attribute to remove\n",
    "\n",
    "**returns** `List`: a copy of `attributes` with `best_attr` removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_minus(attributes, best_attr) -> List:\n",
    "    new_attributes = deepcopy(attributes)\n",
    "    if best_attr in attributes: new_attributes.remove(best_attr)\n",
    "    return new_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "attr = [1, 2, 3, 4]\n",
    "new_attr = attribute_minus(attr, 2)\n",
    "assert new_attr == [1, 3, 4]\n",
    "assert attr == [1, 2, 3, 4]\n",
    "\n",
    "assert attribute_minus([], 1) == []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"add_child\"></a>\n",
    "## add_child\n",
    "\n",
    "`add_child` adds a new node of the form `(best_attr, value, child)` to `node` and returns `node`. This is a helper function to append nodes to the decision tree produced by `id3`. **Used by**: [id3](#id3).\n",
    "\n",
    "* **node**: the current tree\n",
    "* **best_attr**: the new node's attribute\n",
    "* **value**: the new node's attribute's index\n",
    "* **child**: the new node's child/children\n",
    "\n",
    "**returns** `List`: `node` with the new node attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_child(node, best_attr, value, child) -> List:\n",
    "    new_node = deepcopy(node)\n",
    "    new_node.append((deepcopy(best_attr), deepcopy(value), deepcopy(child)))\n",
    "    return new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "node = []\n",
    "new_node = add_child(node, 0, \"e\", [])\n",
    "assert new_node == [(0, \"e\", [])]\n",
    "assert node == []\n",
    "\n",
    "new_node = add_child(node, 1, \"f\", [(2, \"f\", \"e\"), (2, \"x\", \"p\")])\n",
    "assert new_node == [(1, 'f', [(2, 'f', 'e'), (2, 'x', 'p')])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id3\"></a>\n",
    "## id3\n",
    "\n",
    "`id3` is a decision-tree generating algorithm that takes a dataset and returns a decision tree for classification trained on `data`. The recursive algorithm takes a set of training data, a list of current attributes, the domains for all attributes, and a default majority class label. \n",
    "\n",
    "`id3` works by splitting on attributes and creating children for each value in the domain of that attribute - the attributes chosen decrease the entropy of the dataset and slowly bring it closer to homogeneity. In the base case, the dataset passed in is homogeneous, and the class label is the child of the previous node. All leavse of the decision tree have a class label as their children, while interior nodes have a list of nodes as their children. **Uses**: [is_homogeneous](#is_homogeneous), [majority_label](#majority_label), [pick_best_attr](#pick_best_attr), [find_subset](#find_subset), [attribute_minus](#attribute_minus), [add_child](#add_child). **Used by**: [train](#train).\n",
    "\n",
    "* **data**: the training data to build the decision tree from\n",
    "* **attributes**: a list of column indices representing attributes\n",
    "* **domains**: a list of values for every attribute\n",
    "* **default**: the majority class label of `data`.\n",
    "\n",
    "**returns** `List`: a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, attributes, domains, default):\n",
    "    if not data: return default\n",
    "    if is_homogeneous(data): \n",
    "        return deepcopy(data[0][0])\n",
    "    if not attributes: return majority_label(data)\n",
    "    best_attr = pick_best_attr(data, attributes, domains) \n",
    "    node = []\n",
    "    default_label = majority_label(data)\n",
    "    for value in domains[best_attr]: \n",
    "        subset = find_subset(data, best_attr, value)\n",
    "        new_attributes = attribute_minus(attributes, best_attr)\n",
    "        child = id3(subset, new_attributes, domains, default_label)\n",
    "        node = add_child(node, best_attr, value, child)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "data = [['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 's', 'g'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 'r', 's', 'g']]\n",
    "\n",
    "attributes = [1, 2, 3]\n",
    "domains = [['n', 'y'], ['r', 's'], ['l', 's'], ['b', 'g', 'r']]\n",
    "tree = id3(data, attributes, domains, 'n')\n",
    "assert tree == [(2, 'l', 'y'), (2, 's', 'n')]\n",
    "\n",
    "data = [['n', 's', 's', 'r'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['y', 'r', 's', 'r'],\n",
    "        ['n', 's', 'l', 'r'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['n', 's', 's', 'r']]\n",
    "tree = id3(data, attributes, domains, 'n')\n",
    "assert tree == [(1, 'r', 'y'), (1, 's', 'n')]\n",
    "\n",
    "data = [['n', 'r', 'l', 'b'], \n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 'l', 'r'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 'r', 'l', 'r']]\n",
    "tree = id3(data, attributes, domains, 'n')\n",
    "assert tree == [(3, 'b', 'n'), (3, 'g', 'y'), (3, 'r', [(1, 'r', 'y'), (1, 's', 'n')])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## train\n",
    "\n",
    "`train` trains a decision tree from `data` and `domains`. The tree is returned. **Uses**: [majority_label](#majority_label), [id3](#id3). **Used by**: [cross_validate](#cross_validate).\n",
    "\n",
    "* **data**: the training data\n",
    "* **domains**: the domains of `data`\n",
    "\n",
    "**returns** `List`: a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data: List, domains: List) -> List:\n",
    "    attributes = [i for i in range(1, len(data[0]))]\n",
    "    default = majority_label(data)\n",
    "    return id3(deepcopy(data), attributes, domains, default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "data = [['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 's', 'g'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 'r', 's', 'g']]\n",
    "domains = [['n', 'y'], ['r', 's'], ['l', 's'], ['b', 'g', 'r']]\n",
    "assert train(data, domains) == [(2, 'l', 'y'), (2, 's', 'n')]\n",
    "\n",
    "data = [['n', 's', 's', 'r'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['y', 'r', 's', 'r'],\n",
    "        ['n', 's', 'l', 'r'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['n', 's', 's', 'r']]\n",
    "assert train(data, domains) == [(1, 'r', 'y'), (1, 's', 'n')]\n",
    "\n",
    "data = [['n', 'r', 'l', 'b'], \n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 'l', 'r'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 'r', 'l', 'r']]\n",
    "assert train(data, domains) == [(3, 'b', 'n'), (3, 'g', 'y'), (3, 'r', [(1, 'r', 'y'), (1, 's', 'n')])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classify\"></a>\n",
    "## classify\n",
    "\n",
    "`classify` takes a decision tree and a list of observations, and an optional flag for whether the observations are labeled, and returns a list of classifications for every observation. If `labeled` is `False`, a column of `None` values is prepended to the data before classification.\n",
    "\n",
    "The function iteratively matches attributes from the observation in the tree until a leaf node is reached, at which point the child of the leaf node is appended as the classification to the observation. **Used by**: [cross_validate](#cross_validate).\n",
    "\n",
    "* **decision_tree**: the decision tree used for classification\n",
    "* **observations**: the observations to classify\n",
    "* **labeled**: an optional parameter that specifies whether `observations` is labeled\n",
    "\n",
    "**returns** `List`: a list of classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(decision_tree: List, observations: List, labeled=True) -> List:\n",
    "    dataset = deepcopy(observations) if labeled else [[None] + deepcopy(row) for row in observations]\n",
    "    terminated, classifications = False, []\n",
    "    for row in dataset:\n",
    "        child, curr_node = None, decision_tree\n",
    "        while type(child) != str:\n",
    "            for attr, attr_val, child in curr_node:\n",
    "                obs_val = row[attr]\n",
    "                if obs_val == attr_val:\n",
    "                    curr_node = child\n",
    "                    break\n",
    "        classifications.append(child)\n",
    "    return classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "data = [['n', 'r', 'l', 'b'], \n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 's', 'r'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['n', 's', 's', 'b'],\n",
    "        ['n', 'r', 's', 'b'],\n",
    "        ['y', 'r', 's', 'r'],\n",
    "        ['n', 's', 's', 'g'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 'l', 'r'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['n', 's', 's', 'r'],\n",
    "        ['n', 'r', 's', 'g']]\n",
    "attributes = [1, 2, 3]\n",
    "domains = [['n', 'y'], ['r', 's'], ['l', 's'], ['b', 'g', 'r']]\n",
    "tree = id3(data, attributes, domains, 'n')\n",
    "\n",
    "observation = [['n', 's', 's', 'g']]\n",
    "classifications = classify(tree, observation)\n",
    "assert classifications == ['n']\n",
    "\n",
    "observations = [['s', 's', 'r'], ['r', 's', 'b']]\n",
    "classifications = classify(tree, observations, False)\n",
    "assert classifications == ['n', 'n']\n",
    "\n",
    "observations = [deepcopy(row[1:]) for row in data]\n",
    "classifications = classify(tree, observations, False)\n",
    "assert classifications == [row[0] for row in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate\"></a>\n",
    "## evaluate\n",
    "\n",
    "`evaluate` takes a list of classifications and labeled data and returns the error rate of the classifications. Error rate is: \n",
    "$$error\\_rate=\\frac{errors}{n}$$\n",
    "**Used by**: [cross_validate](#cross_validate).\n",
    "\n",
    "* **labeled_data**: the real values for labels to compare to\n",
    "* **classifications**: the estimates to determine error rate for\n",
    "\n",
    "**returns** `float`: the error rate as a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(labeled_data, classifications) -> float:\n",
    "    num_errors = 0\n",
    "    labels = [row[0] for row in labeled_data]\n",
    "    for actual_label, classified_label in zip(labels, classifications):\n",
    "        if actual_label != classified_label: num_errors += 1\n",
    "    return num_errors / len(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "data = [['n', 'r', 'l', 'b'], \n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 's', 'r'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['n', 's', 's', 'b'],\n",
    "        ['n', 'r', 's', 'b'],\n",
    "        ['y', 'r', 's', 'r'],\n",
    "        ['n', 's', 's', 'g'],\n",
    "        ['y', 'r', 'l', 'g'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['n', 's', 'l', 'r'],\n",
    "        ['y', 's', 'l', 'g'],\n",
    "        ['y', 'r', 'l', 'r'],\n",
    "        ['n', 's', 's', 'r'],\n",
    "        ['n', 'r', 's', 'g']]\n",
    "attributes = [1, 2, 3]\n",
    "domains = [['n', 'y'], ['r', 's'], ['l', 's'], ['b', 'g', 'r']]\n",
    "tree = id3(data, attributes, domains, 'n')\n",
    "classifications = classify(tree, data)\n",
    "assert evaluate(data, classifications) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cross_validate\"></a>\n",
    "## cross_validate\n",
    "\n",
    "`cross_validate` takes the data and uses 10 fold cross validation to `train`, `classify`, and `evaluate`. The function shuffles the data, splits the data into folds, and performs 10-fold cross validation on the folds. The error rate for each fold's evaluation is printed, and the average error rate is printed at the end. **Uses**: [create_folds](#create_folds), [create_train_test](#create_train_test), [train](#train), [classify](#classify), [evaluate](#evaluate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(data, domains, classify):\n",
    "    avg_err_rate = 0\n",
    "    random.shuffle(data)\n",
    "    folds = create_folds(data, 10)\n",
    "    for i in range(10):\n",
    "        train_data, test_data = create_train_test(folds, i)\n",
    "        decision_tree = train(train_data, domains)\n",
    "        classifications = classify(decision_tree, test_data)\n",
    "        error_rate = evaluate(test_data, classifications)\n",
    "        print(\"Fold\", i, \"error rate:\", error_rate)\n",
    "        avg_err_rate += error_rate\n",
    "    avg_err_rate = avg_err_rate / 10\n",
    "    print(\"Avg. error rate:\", avg_err_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 error rate: 0.0\n",
      "Fold 1 error rate: 0.0\n",
      "Fold 2 error rate: 0.0\n",
      "Fold 3 error rate: 0.0\n",
      "Fold 4 error rate: 0.0\n",
      "Fold 5 error rate: 0.0\n",
      "Fold 6 error rate: 0.0\n",
      "Fold 7 error rate: 0.0\n",
      "Fold 8 error rate: 0.0\n",
      "Fold 9 error rate: 0.0\n",
      "Avg. error rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "domains = [['e', 'p'], \n",
    "               ['b', 'c', 'x', 'f', 'k', 's'], \n",
    "               ['f', 'g', 'y', 's'], \n",
    "               ['n', 'b', 'c', 'g', 'r', 'p', 'u', 'e', 'w', 'y'], \n",
    "               ['t', 'f'], \n",
    "               ['a', 'l', 'c', 'y', 'f', 'm', 'n', 'p', 's'], \n",
    "               ['a', 'd', 'f', 'n'], \n",
    "               ['c', 'w', 'd'], \n",
    "               ['b', 'n'], \n",
    "               ['k', 'n', 'b', 'h', 'g', 'r', 'o', 'p', 'u', 'e', 'w', 'y'], \n",
    "               ['e', 't'], \n",
    "               ['b', 'c', 'u', 'e', 'z', 'r'], \n",
    "               ['f', 'y', 'k', 's'], \n",
    "               ['f', 'y', 'k', 's'], \n",
    "               ['n', 'b', 'c', 'g', 'o', 'p', 'e', 'w', 'y'], \n",
    "               ['n', 'b', 'c', 'g', 'o', 'p', 'e', 'w', 'y'], \n",
    "               ['p', 'u'], \n",
    "               ['n', 'o', 'w', 'y'], \n",
    "               ['n', 'o', 't'], \n",
    "               ['c', 'e', 'f', 'l', 'n', 'p', 's', 'z'], \n",
    "               ['k', 'n', 'b', 'h', 'r', 'o', 'u', 'w', 'y'], \n",
    "               ['a', 'c', 'n', 's', 'v', 'y'], \n",
    "               ['g', 'l', 'm', 'p', 'u', 'w', 'd']]\n",
    "data = parse_data(\"agaricus-lepiota.data\")\n",
    "cross_validate(data, domains, classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pretty_print_tree\"></a>\n",
    "## pretty_print_tree\n",
    "\n",
    "`pretty_print_tree` prints the given tree in a nested style, with each child denoted by `---->` from the parent. The nodes are printed in order, so indentation specifies which nodes are children of which parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_tree(tree, tabs):\n",
    "#     make it look like this: \n",
    "    tabs_str = \"-\" * (tabs * 4)\n",
    "    tabs_str += '>'\n",
    "    for node in tree:\n",
    "        if type(node[2]) == str: print(tabs_str, node)\n",
    "        else:\n",
    "            print(tabs_str, node[0:2], \"...\")\n",
    "            pretty_print_tree(node[2], tabs + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> (5, 'a', 'e')\n",
      "> (5, 'l', 'e')\n",
      "> (5, 'c', 'p')\n",
      "> (5, 'y', 'p')\n",
      "> (5, 'f', 'p')\n",
      "> (5, 'm', 'p')\n",
      "> (5, 'n') ...\n",
      "----> (20, 'k', 'e')\n",
      "----> (20, 'n', 'e')\n",
      "----> (20, 'b', 'e')\n",
      "----> (20, 'h', 'e')\n",
      "----> (20, 'r', 'p')\n",
      "----> (20, 'o', 'e')\n",
      "----> (20, 'u', 'e')\n",
      "----> (20, 'w') ...\n",
      "--------> (3, 'n', 'e')\n",
      "--------> (3, 'b', 'e')\n",
      "--------> (3, 'c', 'e')\n",
      "--------> (3, 'g', 'e')\n",
      "--------> (3, 'r', 'e')\n",
      "--------> (3, 'p', 'e')\n",
      "--------> (3, 'u', 'e')\n",
      "--------> (3, 'e', 'e')\n",
      "--------> (3, 'w', 'p')\n",
      "--------> (3, 'y', 'p')\n",
      "----> (20, 'y', 'e')\n",
      "> (5, 'p', 'p')\n",
      "> (5, 's', 'p')\n"
     ]
    }
   ],
   "source": [
    "tree = train(data, domains)\n",
    "pretty_print_tree(tree, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
