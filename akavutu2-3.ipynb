{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k Nearest Neighbors and Model Evaluation\n",
    "\n",
    "In this programming assignment you will use k Nearest Neighbors (kNN) to build a \"model\" that will estimate the compressive strength of various types of concrete. This assignment has several objectives:\n",
    "\n",
    "1. Implement the kNN algorithm with k=9. Remember...the data + distance function is the model in kNN. In addition to asserts that unit test your code, you should \"test drive\" the model, showing output that a non-technical person could interpret.\n",
    "\n",
    "2. You are going to compare the kNN model above against the baseline model described in the course notes (the mean of the training set's target variable). You should use 10 fold cross validation and Mean Squared Error (MSE):\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum^n_i (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "as the evaluation metric (\"error\"). Refer to the course notes for the format your output should take. Don't forget a discussion of the results.\n",
    "\n",
    "3. use validation curves to tune a *hyperparameter* of the model. \n",
    "In this case, the hyperparameter is *k*, the number of neighbors. Don't forget a discussion of the results.\n",
    "\n",
    "4. evaluate the *generalization error* of the new model.\n",
    "Because you may have just created a new, better model, you need a sense of its generalization error, calculate that. Again, what would you like to see as output here? Refer to the course notes. Don't forget a discussion of the results. Did the new model do better than either model in Q2?\n",
    "\n",
    "5. pick one of the \"Choose Your Own Adventure\" options.\n",
    "\n",
    "Refer to the \"course notes\" for this module for most of this assignment.\n",
    "Anytime you just need test/train split, use fold index 0 for the test set and the remainder as the training set.\n",
    "Discuss any results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "The function `parse_data` loads the data from the specified file and returns a List of Lists. The outer List is the data set and each element (List) is a specific observation. Each value of an observation is for a particular measurement. This is what we mean by \"tidy\" data.\n",
    "\n",
    "The function also returns the *shuffled* data because the data might have been collected in a particular order that *might* bias training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Dict, Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> List[List]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [float(value) for value in line.rstrip().split(\",\")]\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse_data(\"concrete_compressive_strength.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[540.0, 0.0, 0.0, 162.0, 2.5, 1055.0, 676.0, 28.0, 61.89]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,030 observations and each observation has 8 measurements. The data dictionary for this data set tells us the definitions of the individual variables (columns/indices):\n",
    "\n",
    "| Index | Variable | Definition |\n",
    "|-------|----------|------------|\n",
    "| 0     | cement   | kg in a cubic meter mixture |\n",
    "| 1     | slag     | kg in a cubic meter mixture |\n",
    "| 2     | ash      | kg in a cubic meter mixture |\n",
    "| 3     | water    | kg in a cubic meter mixture |\n",
    "| 4     | superplasticizer | kg in a cubic meter mixture |\n",
    "| 5     | coarse aggregate | kg in a cubic meter mixture |\n",
    "| 6     | fine aggregate | kg in a cubic meter mixture |\n",
    "| 7     | age | days |\n",
    "| 8     | concrete compressive strength | MPa |\n",
    "\n",
    "The target (\"y\") variable is a Index 8, concrete compressive strength in (Mega?) [Pascals](https://en.wikipedia.org/wiki/Pascal_(unit))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Splits - n folds\n",
    "\n",
    "With n fold cross validation, we divide our data set into n subgroups called \"folds\" and then use those folds for training and testing. You pick n based on the size of your data set. If you have a small data set--100 observations--and you used n=10, each fold would only have 10 observations. That's probably too small. You want at least 30. At the other extreme, we generally don't use n > 10.\n",
    "\n",
    "With 1,030 observations, n = 10 is fine so we will have 10 folds.\n",
    "`create_folds` will take a list (xs) and split it into `n` equal folds with each fold containing one-tenth of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(xs: List, n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(xs), n)\n",
    "    # be careful of generators...\n",
    "    return list(xs[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = create_folds(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always use one of the n folds as a test set (and, sometimes, one of the folds as a *pruning* set but not for kNN), and the remaining folds as a training set.\n",
    "We need a function that'll take our n folds and return the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(folds: List[List[List]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the function to give us a train and test datasets where the test set is the fold at index 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = create_train_test(folds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "\n",
    "Answer the questions above in the space provided below, adding cells as you need to.\n",
    "Put everything in the helper functions and document them.\n",
    "Document everything (what you're doing and why).\n",
    "If you're not sure what format the output should take, refer to the course notes and what they do for that particular topic/algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: kNN\n",
    "\n",
    "Implement k Nearest Neighbors with k = 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"distance\"></a>\n",
    "### distance\n",
    "\n",
    "`distance` calculates the Euclidian distance between `example` and `query` for every dimension. The formula for the Euclidian distance is: $$ d(a, b) = \\sqrt{\\sum_i ^n (a_i - b_i)^2}$$\n",
    "for every dimension $i$ in the `example` and `query`. The distance is used as a measure of \"nearness\" for use in the `kNN` algorithm below. **Used by**: [kNN](#kNN)\n",
    "\n",
    "* **example**: a list of features used as the reference point\n",
    "* **query**: a list of features used as the query point\n",
    "\n",
    "**returns** float: the Euclidian distance between `example` and `query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(example: List[float], query: List[float]) -> float:\n",
    "    dist = 0\n",
    "    for example_val, query_val in zip(example, query):\n",
    "        dist += (example_val - query_val) ** 2\n",
    "    return sqrt(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "x = [1, 1]\n",
    "y = [2, 2]\n",
    "actual_dist = distance(x, y)\n",
    "assert actual_dist == sqrt(2)\n",
    "\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [5, 4, 3, 2, 1]\n",
    "actual_dist = distance(x, y)\n",
    "assert actual_dist == sqrt(40)\n",
    "\n",
    "x, y = [], []\n",
    "actual_dist = distance(x, y)\n",
    "assert actual_dist == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"processing\"></a>\n",
    "### processing\n",
    "\n",
    "`processing` takes a list of the nearest neighbors to a query point (`nearest`) and a number of features in each example, and computes the mean of the target values for each example in `nearest`. This function is one example of how a list of nearest-neighbors can be processed - for use in a regression problem, this `processing` function works well. However, for use in a classification problem, the function must be adapted to return the majority class label, or some other metric of the `target` for the closest `k` neighbors. **Used by**: [kNN](#kNN)\n",
    "\n",
    "* **nearest**: a list of the k-nearest neighbors to process\n",
    "* **num_features**: the number of features in each example\n",
    "\n",
    "**returns** float: the mean value of the `target` variable from `nearest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(nearest: List[Tuple[float, List[float]]], num_features: int) -> float:\n",
    "    if nearest:\n",
    "        yvals = [examples[1][num_features] for examples in nearest]\n",
    "        return sum(yvals) / len(yvals)\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "nearest = [(1, [1, 1, 1]), (2, [2, 2, 2]), (3, [3, 3, 3])]\n",
    "actual_mean = processing(nearest, 2)\n",
    "assert actual_mean == 2\n",
    "\n",
    "assert processing([], 2) == 0\n",
    "\n",
    "nearest = [(1, [1, 1, 1, 5]), (2, [2, 2, 2, 13]), (3, [3, 3, 3, 21])]\n",
    "actual_mean = processing(nearest, 3)\n",
    "assert actual_mean == 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"knn\"></a>\n",
    "### knn\n",
    "\n",
    "`knn` is the k-Nearest-Neighbors algorithm, which takes a `dataset`, a `query` point, and a `k` value and finds the `k` nearest points to `query` in `dataset`. The algorithm then returns the mean value of the `y` measurement from those neighbors as a guess for what the `query` point's `y` value will be. This implementation is used to solve a regression problem; as mentioned above, the `processing` and `distance` functions can be changed to allow for this function to solve a classification problem, as well. \n",
    "\n",
    "`kNN` is a classic example of a lazy machine learning algorithm - this algorithm takes a training set of data and uses it as the model to predict the test data. In eager algorithms, the algorithm might take training data and augment the model/\"learn\" from the training data, before being applied to the test data. **Uses**: [distance](#distance), [processing](#processing).\n",
    "\n",
    "* **dataset**: the set of examples over which to find the nearest neighbors to `query`\n",
    "* **query**: the point to which the k-nearest neighbors are found\n",
    "* **k**: the number of nearest-neighbors to process\n",
    "* **num_features**: the number of features in each example of `dataset`\n",
    "\n",
    "**returns** float: the mean value of the `target` variable in the k-nearest neighbors to `query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(dataset: List[List], query: List, k: int, num_features: int) -> float:\n",
    "    distances = []\n",
    "    for example in dataset:\n",
    "        curr_distance = distance(example[:num_features], query[:num_features])\n",
    "        distances.append((curr_distance, example))\n",
    "    distances = sorted(distances)\n",
    "    nearest = distances[:k]\n",
    "    return processing(nearest, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "dataset = [[0.23, 0.81, 0.18], [0.42, 0.78, 0.33], [0.64, 0.23, 0.14], [0.87, 0.19, 0.17], [0.76, 0.43, 0.32]]\n",
    "query = [0.39, 0.63, 0]\n",
    "estimate = knn(dataset, query, 3, 2)\n",
    "assert abs(estimate - 0.276) < 0.01\n",
    "\n",
    "query = [0.39, 0.63, 0] \n",
    "estimate = knn(dataset, query, 8, 2)\n",
    "assert abs(estimate - 0.228) < 0.01\n",
    "\n",
    "query = [0.23, 0.81, 0]\n",
    "estimate = knn(dataset, query, 1, 2)\n",
    "assert estimate == 0.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "These are 10 example runs using `kNN` to find the nearest neighbors to query points. These query points were chosen from the provided dataset. The features of each query, as well as the actual target value and expected target value, are printed in each line. As we can see, there is a strong correlation between the expected and actual values - most values are within 5-10 of the actual target value, and only a few are further than that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [190, 190, 0, 228, 0, 932, 670, 90] Actual y: 42.33 Estimated y: 40.565555555555555\n",
      "Features: [304, 76, 0, 228, 0, 932, 670, 28] Actual y: 47.81 Estimated y: 45.781111111111116\n",
      "Features: [380, 0, 0, 228, 0, 932, 670, 90] Actual y: 52.91 Estimated y: 49.112222222222215\n",
      "Features: [139.6, 209.4, 0, 192, 0, 1047, 806.9, 90] Actual y: 39.36 Estimated y: 26.584444444444443\n",
      "Features: [342, 38, 0, 228, 0, 932, 670, 365] Actual y: 56.14 Estimated y: 51.885555555555555\n",
      "Features: [380, 95, 0, 228, 0, 932, 594, 90] Actual y: 40.56 Estimated y: 38.97333333333333\n",
      "Features: [475, 0, 0, 228, 0, 932, 594, 180] Actual y: 42.62 Estimated y: 44.46\n",
      "Features: [427.5, 47.5, 0, 228, 0, 932, 594, 180] Actual y: 41.84 Estimated y: 42.97888888888889\n",
      "Features: [139.6, 209.4, 0, 192, 0, 1047, 806.9, 28] Actual y: 28.24 Estimated y: 22.506666666666668\n",
      "Features: [139.6, 209.4, 0, 192, 0, 1047, 806.9, 3] Actual y: 8.06 Estimated y: 21.774444444444445\n"
     ]
    }
   ],
   "source": [
    "# print features / actual y / estimate y\n",
    "test_data = parse_data(\"concrete_compressive_strength.csv\")\n",
    "queries = [[190, 190, 0, 228, 0, 932, 670, 90, 42.33],\n",
    "          [304, 76, 0, 228, 0, 932, 670, 28, 47.81],\n",
    "          [380, 0, 0, 228, 0, 932, 670, 90, 52.91],\n",
    "          [139.6, 209.4, 0, 192, 0, 1047, 806.9, 90, 39.36],\n",
    "          [342, 38, 0, 228, 0, 932, 670, 365, 56.14],\n",
    "          [380, 95, 0, 228, 0, 932, 594, 90, 40.56],\n",
    "          [475, 0, 0, 228, 0, 932, 594, 180, 42.62],\n",
    "          [427.5, 47.5, 0, 228, 0, 932, 594, 180, 41.84],\n",
    "          [139.6, 209.4, 0, 192, 0, 1047, 806.9, 28, 28.24],\n",
    "          [139.6, 209.4, 0, 192, 0, 1047, 806.9, 3, 8.06]]\n",
    "\n",
    "for query in queries:\n",
    "    estimate = knn(test_data, query, 9, 8)\n",
    "    print(\"Features:\", query[:8], \"Actual y:\", query[8], \"Estimated y:\", estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Evaluation vs. The Mean\n",
    "\n",
    "Using Mean Squared Error (MSE) as your evaluation metric, evaluate your implement above and the Null model, the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mse\"></a>\n",
    "### mse\n",
    "\n",
    "`mse` takes in a list of `actuals` values and a list of `estimates` and computes the mean squared error from the two. The formula for mean squared error is: $$MSE = \\frac1n \\sum_i^n (y_i - \\hat{y}_i)^2 $$\n",
    "The $y_i$ represents the estimate value for the target variable, and $\\hat{y}_i$ represents the actual target value. Mean squared error is a suitable evaluation metric for a regression model, and is therefore useful in determining whether our `kNN` model is performing well. \n",
    "\n",
    "* **actuals**: the list of actual target values\n",
    "* **estimates**: the list of estimate target values (`kNN` or `Null` model)\n",
    "\n",
    "**returns** float: the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(actuals: List[float], estimates: List[float]) -> float:\n",
    "    mse = 0\n",
    "    for yval, y_hat in zip(actuals, estimates):\n",
    "        mse += ((yval - y_hat) ** 2)\n",
    "    return mse / len(actuals) if actuals else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "actuals = [1, 2, 3, 4, 5]\n",
    "estimates = [2, 3, 4, 5, 6]\n",
    "actual_mse = mse(actuals, estimates)\n",
    "assert actual_mse == 1\n",
    "\n",
    "actuals, estimates = [], []\n",
    "actual_mse = mse(actuals, estimates)\n",
    "assert actual_mse == 0\n",
    "\n",
    "actuals, estimates = [1, 3, 5, 7], [0, 0, 0, 0]\n",
    "actual_mse = mse(actuals, estimates)\n",
    "assert actual_mse == (1 + 9 + 25 + 49) / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE for Null and kNN\n",
    "\n",
    "Below, we use 10-fold cross validation to compare the mean squared error for the Null model and the `kNN` model. By comparing the MSE values for `kNN` model to the `Null` model, which simply takes the average `target` value from the `train` set as the estimate for each `test` query, we can determine the strength of the `kNN` model. \n",
    "\n",
    "In 10-fold cross validation, we split our dataset into folds of equal size, and iteratively choose each fold to be the test set, with the remaining folds as the training set. For example, the first iteration for 10-fold cross validation chooses Fold 0 as the test set, with Folds 1-9 as the training set. The second iteration chooses Fold 1 as the test set, with Fold 0 and Folds 2-9 as the training set, and so on. By using this method, we can simulate a larger data set and avoid issues with not being able to test often with the test set. Additionally, this method will minimize the bias of the model towards the training set, as the training set changes in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 mean squared error: 294.65980034608407\n",
      "Fold 1 mean squared error: 299.9913112267828\n",
      "Fold 2 mean squared error: 234.54835035638263\n",
      "Fold 3 mean squared error: 334.6203727873724\n",
      "Fold 4 mean squared error: 276.1753498438898\n",
      "Fold 5 mean squared error: 288.4063566222018\n",
      "Fold 6 mean squared error: 353.2738528649678\n",
      "Fold 7 mean squared error: 264.3624029031954\n",
      "Fold 8 mean squared error: 245.91779372207847\n",
      "Fold 9 mean squared error: 202.90563530964272\n",
      "Mean: 279.4861225982598\n"
     ]
    }
   ],
   "source": [
    "avg_mse = 0\n",
    "num_features = 8\n",
    "folds = create_folds(data, 10)\n",
    "for i in range(10):\n",
    "    train, test = create_train_test(folds, i)\n",
    "    yvals_train = [row[num_features] for row in train]\n",
    "    yvals_test = [row[num_features] for row in test]\n",
    "    \n",
    "    null_estimate = sum(yvals_train) / len(yvals_train)\n",
    "    null_model = [null_estimate for i in range(len(yvals_test))]\n",
    "    null_mse_test = mse(yvals_test, null_model)\n",
    "    print(\"Fold\", i, \"mean squared error:\", null_mse_test)\n",
    "    avg_mse += null_mse_test\n",
    "avg_mse = avg_mse / 10\n",
    "print(\"Mean:\", avg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 mean squared error: 97.64360571736785\n",
      "Fold 1 mean squared error: 100.95857020256497\n",
      "Fold 2 mean squared error: 76.467262843102\n",
      "Fold 3 mean squared error: 123.7262231331656\n",
      "Fold 4 mean squared error: 62.8892702744816\n",
      "Fold 5 mean squared error: 71.29839507371453\n",
      "Fold 6 mean squared error: 105.85194104039313\n",
      "Fold 7 mean squared error: 116.19289779455829\n",
      "Fold 8 mean squared error: 74.29949131008031\n",
      "Fold 9 mean squared error: 68.54594201126696\n",
      "Mean: 89.78735994006952\n"
     ]
    }
   ],
   "source": [
    "avg_mse = 0\n",
    "num_features, k = 8, 9\n",
    "folds = create_folds(data, 10)\n",
    "for i in range(10):\n",
    "    train, test = create_train_test(folds, i)\n",
    "    yvals_train = [row[num_features] for row in train]\n",
    "    yvals_test = [row[num_features] for row in test]\n",
    "    \n",
    "    knn_estimates = [knn(train, query, k, num_features) for query in test]\n",
    "    knn_mse_test = mse(yvals_test, knn_estimates)\n",
    "    print(\"Fold\", i, \"mean squared error:\", knn_mse_test)\n",
    "    avg_mse += knn_mse_test\n",
    "avg_mse = avg_mse / 10\n",
    "print(\"Mean:\", avg_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Evaluation\n",
    "\n",
    "As we can see, the Null model has a very high mean squared error, with an average MSE of ~279, whereas the `kNN` model has an average MSE of ~90. These measurements verify that our `kNN` model is a strong improvement over the Null model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Hyperparameter Tuning\n",
    "\n",
    "Tune the value of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 8\n",
    "folds = create_folds(data, 10)\n",
    "train, test = create_train_test(folds, 0)\n",
    "yvals_test = [row[num_features] for row in test]\n",
    "mean_mse_train = []\n",
    "mean_mse_test = []\n",
    "for k in range(1, 21):\n",
    "    train_estimates = [knn(train, query, k, num_features) for query in test]\n",
    "    mean_mse_train.append(mse(yvals_test, train_estimates))\n",
    "    test_estimates = [knn(test, query, k, num_features) for query in test]\n",
    "    mean_mse_test.append(mse(yvals_test, test_estimates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "xvals = [i for i in range(1, 21)]\n",
    "plt.plot(xvals, mean_mse_train, label=\"train\")\n",
    "plt.plot(xvals, mean_mse_test, label=\"test\")\n",
    "plt.legend()\n",
    "plt.title(\"Validation Curves\")\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Validation Curves\n",
    "\n",
    "From the validation curves, we can see that there is a slight inflection in the training set graph at around $k=3$. After this point, around $k = 8$ and above, the test set error is much higher than the training set error, which indicates overfitting. At the lower end, we have a different situation - both the test and training set errors are similar, and somewhat low (for $2 < k < 6$). This is the ideal zone for our hyperparameter, so we will choose the lowest error in this area, which is around $k = 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Generalization Error\n",
    "\n",
    "Analyze and discuss the generalization error of your model with the value of k from Problem 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 mean squared error: 69.05400442286945\n",
      "Fold 1 mean squared error: 112.29218112189857\n",
      "Fold 2 mean squared error: 65.12020064724922\n",
      "Fold 3 mean squared error: 101.02163969795046\n",
      "Fold 4 mean squared error: 51.947670981661275\n",
      "Fold 5 mean squared error: 68.1319439050701\n",
      "Fold 6 mean squared error: 70.55255749730313\n",
      "Fold 7 mean squared error: 92.10108608414238\n",
      "Fold 8 mean squared error: 65.18143128371091\n",
      "Fold 9 mean squared error: 70.19067055016178\n",
      "Mean: 76.55933861920174\n"
     ]
    }
   ],
   "source": [
    "k, avg_mse = 3, 0\n",
    "num_features = 8\n",
    "folds = create_folds(data, 10)\n",
    "for i in range(10):\n",
    "    train, test = create_train_test(folds, i)\n",
    "    yvals_train = [row[num_features] for row in train]\n",
    "    yvals_test = [row[num_features] for row in test]\n",
    "    \n",
    "    knn_estimates = [knn(train, query, k, num_features) for query in test]\n",
    "    knn_mse_test = mse(yvals_test, knn_estimates)\n",
    "    print(\"Fold\", i, \"mean squared error:\", knn_mse_test)\n",
    "    avg_mse += knn_mse_test\n",
    "avg_mse = avg_mse / 10\n",
    "print(\"Mean:\", avg_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Generalization\n",
    "\n",
    "After tuning our hyperparameter to $k = 3$, we see that our generalization error drops by about 10 to a value of 77. This marked improvement further validates that our hyperparameter tuning was a success and improved our model. Going forward, we will use a value of $k = 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Choose your own adventure\n",
    "\n",
    "You have three options for the next part:\n",
    "\n",
    "1. You can implement mean normalization (also called \"z-score standardization\") of the *features*; do not normalize the target, y. See if this improves the generalization error of your model (middle).\n",
    "\n",
    "2. You can implement *learning curves* to see if more data would likely improve your model (easiest).\n",
    "\n",
    "3. You can implement *weighted* kNN and use the real valued GA to choose the weights. weighted kNN assigns a weight to each item in the Euclidean distance calculation. For two points, j and k:\n",
    "$$\\sqrt{\\sum w_i (x^k_i - x^j_i)^2}$$\n",
    "\n",
    "You can think of normal Euclidean distance as the case where $w_i = 1$ for all features  (ambitious, but fun...you need to start EARLY because it takes a really long time to run).\n",
    "\n",
    "The easier the adventure the more correct it must be..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"feature_scale\"></a>\n",
    "### feature_scale\n",
    "\n",
    "`feature_scale` takes a set of data and a number of features and scales each feature by the below formula for Z-Score Standardization: $$x' = \\frac{x - \\bar{X}}{stdev(X)}$$\n",
    "\n",
    "We take each value $x$ in the feature and we subtract the mean and divide by the standard deviation of the feature. The function then returns a new scaled data set. The `unscaled_data` comes in with rows as examples, so the data is transposed before applying mean normalization (so each row is a feature), and then transposed again at the end.\n",
    "\n",
    "Feature scaling comes in many forms, and mean normalization is one of these forms. Alternatives include mean normalization, which divides by the range rather than the standard deviation, and unit-length scaling, which scales each feature by the length of the feature vector. All feature scaling methods seek to improve model performance by limiting the effect of large variability in any one feature on the final distance calculation. By scaling each feature by its relative spread, we ensure that the values of `x'` are much less variable than the originals, and therefore all features have equal weight on the final distance metric.\n",
    "\n",
    "* **unscaled_data**: the set of data to be scaled, with each row as one feature\n",
    "* **num_features**: the number of features to be scaled in `unscaled_data`\n",
    "\n",
    "**returns** `List[List]`: the data set scaled with mean normalization, with rows as examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scale(unscaled_data: List[List], num_features: int) -> List[List]:\n",
    "    scaled_data = []\n",
    "    new_data = list(map(list, zip(*unscaled_data)))\n",
    "    for row in new_data[:num_features]:\n",
    "        min_x, max_x = min(row), max(row)\n",
    "        std_dev = stdev(row) if stdev(row) > 0 else 1\n",
    "        mean_x = sum(row) / len(row)\n",
    "        new_row = [(x - mean_x) / std_dev for x in row]\n",
    "        scaled_data.append(new_row)\n",
    "    if new_data: scaled_data.append(new_data[num_features])\n",
    "    scaled_data = map(list, zip(*scaled_data))\n",
    "    return list(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "test_data = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
    "actual_scaled = feature_scale(test_data, 2)\n",
    "assert actual_scaled[0][2] == 3\n",
    "\n",
    "test_data = []\n",
    "actual_scaled = feature_scale(test_data, 2)\n",
    "assert actual_scaled == []\n",
    "\n",
    "test_data = [[5, 4, 3], [5, 4, 3], [5, 4, 3], [5, 4, 3]]\n",
    "actual_scaled = feature_scale(test_data, 2)\n",
    "assert actual_scaled == [[0.0, 0.0, 3] for i in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score Standardization\n",
    "\n",
    "To further improve our model, we can normalize the data using Z-Score Standardization. For each feature of the data, we can perform the transformation detailed above.\n",
    "By normalizing values, we ensure that if there is a wide range of values for any one feature, that feature does not dominate the overall final distance calculation, which should increase the overall performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 mean squared error: 67.63188683926644\n",
      "Fold 1 mean squared error: 119.81918306364615\n",
      "Fold 2 mean squared error: 67.71787508090614\n",
      "Fold 3 mean squared error: 103.75879838187706\n",
      "Fold 4 mean squared error: 51.81019126213591\n",
      "Fold 5 mean squared error: 77.55894250269688\n",
      "Fold 6 mean squared error: 60.08533969795036\n",
      "Fold 7 mean squared error: 69.55175134843581\n",
      "Fold 8 mean squared error: 64.97058770226538\n",
      "Fold 9 mean squared error: 69.57776483279396\n",
      "Mean: 75.2482320711974\n"
     ]
    }
   ],
   "source": [
    "# supporting code and discussion\n",
    "avg_mse = 0\n",
    "num_features = 8\n",
    "k = 3\n",
    "folds = create_folds(data, 10)\n",
    "for i in range(10):\n",
    "    train, test = create_train_test(folds, i)\n",
    "    yvals_train = [row[num_features] for row in train]\n",
    "    yvals_test = [row[num_features] for row in test]\n",
    "    \n",
    "    train = feature_scale(train, num_features)\n",
    "    test = feature_scale(test, num_features)\n",
    "    \n",
    "    knn_estimates = [knn(train, query, k, num_features) for query in test]\n",
    "    knn_mse_test = mse(yvals_test, knn_estimates)\n",
    "    print(\"Fold\", i, \"mean squared error:\", knn_mse_test)\n",
    "    avg_mse += knn_mse_test\n",
    "avg_mse = avg_mse / 10\n",
    "print(\"Mean:\", avg_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Z-Score Standardization\n",
    "\n",
    "Although the impact of feature scaling is not large, there is still a slight decrease from the non-normalized model. The reason for a less noticeable impact might be that the data is largely clumped around the mean, meaning that the normalization does not change the values greatly. However, in other problems where the values of each feature might be more varied, mean normalization would have a larger impact on the overall performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "117px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
